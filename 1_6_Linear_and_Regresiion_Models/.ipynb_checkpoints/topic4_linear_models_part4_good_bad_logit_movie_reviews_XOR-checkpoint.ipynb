{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Отворен курс за машинно обучение\n",
    "\n",
    "Автор: [Юрий Кашницки](https://yorko.github.io). Превод и редакция от [Christina Butsko](https://www.linkedin.com/in/christinabutsko/), [Nerses Bagiyan](https://www.linkedin.com/in/nersesbagiyan/), [Yulia Klimushina] (https://www.linkedin.com/in/yuliya-klimushina-7168a9139) и [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/). Този материал е предмет на правилата и условията на лиценза [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Безплатното използване е разрешено за всякакви нетърговски цели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 4. Линейна класификация и регресия\n",
    "## <center> Част 4. Къде логистичната регресия е добра и къде не\n",
    "    \n",
    "            \n",
    "## Описание на статията\n",
    "1. [Анализ на рецензии за филми в IMDB](#1.-Анализ-на-ревюта-на-IMDB-филми)\n",
    "2. [Просто броене на думи](#2.-Просто броене-на-думи)\n",
    "3. [XOR-Проблем](#3.-XOR-Проблем)\n",
    "4. [Демо задание](#4.-Демо-задаване)\n",
    "5. [Полезни ресурси](#5.-Полезни-ресурси)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Анализ на рецензии за филми в IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сега за малко практика! Искаме да разрешим проблема с двоичната класификация на рецензиите на филми в IMDB. Имаме тренировъчен комплект с отбелязани отзиви, 12500 отзива, маркирани като добри, още 12500 лоши. Тук не е лесно да започнем с машинното обучение веднага, защото нямаме матрицата $X$; трябва да го подготвим. Ще използваме прост подход: модел на торба с думи. Характеристиките на рецензията ще бъдат представени чрез индикатори за наличието на всяка дума от целия корпус в тази рецензия. Корпусът е набор от всички потребителски рецензии. Идеята е илюстрирана със снимка\n",
    "<img src=\"../../img/bag_of_words.svg\" width=80% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**За да започнете, автоматично изтегляме набора от данни от [тук](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) и го деархивираме заедно с останалите набори от данни в папка с данни. Наборът от данни е описан накратко [тук](http://ai.stanford.edu/~amaas/data/sentiment/). Има 12,5 хиляди добри и лоши отзиви в тестовите и тренировъчни комплекти.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset from:   http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "\n",
    "def load_imdb_dataset(extract_path=\"../../data\", overwrite=False):\n",
    "    # check if existed already\n",
    "    if (\n",
    "        os.path.isfile(os.path.join(extract_path, \"aclImdb\", \"README\"))\n",
    "        and not overwrite\n",
    "    ):\n",
    "        print(\"IMDB dataset is already in place.\")\n",
    "        return\n",
    "\n",
    "    print(\"Downloading the dataset from:  \", url)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    tar = tarfile.open(mode=\"r:gz\", fileobj=BytesIO(response.content))\n",
    "\n",
    "    data = tar.extractall(extract_path)\n",
    "\n",
    "\n",
    "load_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# change if you have it in alternative location\u001b[39;00m\n\u001b[1;32m      2\u001b[0m PATH_TO_IMDB \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/aclImdb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m reviews_train \u001b[38;5;241m=\u001b[39m load_files(\n\u001b[1;32m      5\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH_TO_IMDB, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m), categories\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m text_train, y_train \u001b[38;5;241m=\u001b[39m reviews_train\u001b[38;5;241m.\u001b[39mdata, reviews_train\u001b[38;5;241m.\u001b[39mtarget\n\u001b[1;32m      9\u001b[0m reviews_test \u001b[38;5;241m=\u001b[39m load_files(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH_TO_IMDB, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m), categories\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_files' is not defined"
     ]
    }
   ],
   "source": [
    "# change if you have it in alternative location\n",
    "PATH_TO_IMDB = \"../../data/aclImdb\"\n",
    "\n",
    "reviews_train = load_files(\n",
    "    os.path.join(PATH_TO_IMDB, \"train\"), categories=[\"pos\", \"neg\"]\n",
    ")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "\n",
    "reviews_test = load_files(os.path.join(PATH_TO_IMDB, \"test\"), categories=[\"pos\", \"neg\"])\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Алтернативно, заредете данни от предварително избрани обекти.\n",
    "# import pickle\n",
    "# с open('../../data/imdb_text_train.pkl', 'rb') as f:\n",
    "# text_train = pickle.load(f)\n",
    "# с open('../../data/imdb_text_test.pkl', 'rb') as f:\n",
    "# text_test = pickle.load(f)\n",
    "# с open('../../data/imdb_target_train.pkl', 'rb') as f:\n",
    "# y_train = pickle.load(f)\n",
    "# с open('../../data/imdb_target_test.pkl', 'rb') as f:\n",
    "# y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in training data: 25000\n",
      "[12500 12500]\n",
      "Number of documents in test data: 25000\n",
      "[12500 12500]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))\n",
    "print(\"Number of documents in test data: %d\" % len(text_test))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ето няколко примера за отзиви.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.'\n"
     ]
    }
   ],
   "source": [
    "print(text_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]  # bad review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Everyone plays their part pretty well in this \"little nice movie\". Belushi gets the chance to live part of his life differently, but ends up realizing that what he had was going to be just as good or maybe even better. The movie shows us that we ought to take advantage of the opportunities we have, not the ones we do not or cannot have. If U can get this movie on video for around $10, it\\xc2\\xb4d be an investment!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]  # good review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../../data/imdb_text_train.pkl', 'wb') as f:\n",
    "#     pickle.dump(text_train, f)\n",
    "# with open('../../data/imdb_text_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(text_test, f)\n",
    "# with open('../../data/imdb_target_train.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_train, f)\n",
    "# with open('../../data/imdb_target_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Просто броене на думи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Първо ще създадем речник на всички думи с помощта на CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74849"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(text_train)\n",
    "\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ако погледнете примерите за „думи“ (да ги наречем токени), можете да видите, че сме пропуснали много от важните стъпки в обработката на текст (самата автоматична обработка на текст може да бъде напълно отделна поредица от статии).* *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.get_feature_names()[:50])\n",
    "print(cv.get_feature_names()[50000:50050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Второ, ние кодираме изреченията от текстовете на учебния набор с индексите на входящите думи. Ще използваме разредения формат.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нека да видим как работи нашата трансформация**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_train[19726])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[19726].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[19726].nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Трето, ще приложим същите операции към тестовия набор**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv.transform(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Следващата стъпка е да обучите логистична регресия.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(solver=\"lbfgs\", n_jobs=-1, random_state=7)\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нека да разгледаме точността както на комплектите за обучение, така и на тестовите.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(logit.score(X_train, y_train), 3), round(logit.score(X_test, y_test), 3),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Коефициентите на модела могат да бъдат красиво показани.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_coefficients(classifier, feature_names, n_top_features=25):\n",
    "    # get coefficients with large absolute values\n",
    "    coef = classifier.coef_.ravel()\n",
    "    positive_coefficients = np.argsort(coef)[-n_top_features:]\n",
    "    negative_coefficients = np.argsort(coef)[:n_top_features]\n",
    "    interesting_coefficients = np.hstack([negative_coefficients, positive_coefficients])\n",
    "    # plot them\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coef[interesting_coefficients]]\n",
    "    plt.bar(np.arange(2 * n_top_features), coef[interesting_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(\n",
    "        np.arange(1, 1 + 2 * n_top_features),\n",
    "        feature_names[interesting_coefficients],\n",
    "        rotation=60,\n",
    "        ha=\"right\",\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_scores(grid, param_name):\n",
    "    plt.plot(\n",
    "        grid.param_grid[param_name],\n",
    "        grid.cv_results_[\"mean_train_score\"],\n",
    "        color=\"green\",\n",
    "        label=\"train\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        grid.param_grid[param_name],\n",
    "        grid.cv_results_[\"mean_test_score\"],\n",
    "        color=\"red\",\n",
    "        label=\"test\",\n",
    "    )\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_coefficients(logit, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**За да направим нашия модел по-добър, можем да оптимизираме коефициента на регулация за „Логистичната регресия“. Ще използваме `sklearn.pipeline`, тъй като `CountVectorizer` трябва да се прилага само към данните за обучение (за да не \"надникваме\" в тестовия набор и да не броим честотите на думите там). В този случай `pipeline` определя правилната последователност от действия: приложете `CountVectorizer`, след това обучете `Logistic Regression`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "text_pipe_logit = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    # for some reason n_jobs > 1 won't work\n",
    "    # with GridSearchCV's n_jobs > 1\n",
    "    LogisticRegression(solver=\"lbfgs\", n_jobs=1, random_state=7),\n",
    ")\n",
    "\n",
    "text_pipe_logit.fit(text_train, y_train)\n",
    "print(text_pipe_logit.score(text_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_logit = {\"logisticregression__C\": np.logspace(-5, 0, 6)}\n",
    "grid_logit = GridSearchCV(\n",
    "    text_pipe_logit, param_grid_logit, return_train_score=True, cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_logit.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нека отпечатаме най-добрия $C$ и cv-резултат, използвайки този хиперпараметър:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logit.best_params_, grid_logit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_scores(grid_logit, \"logisticregression__C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За набора за валидиране:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logit.score(text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Сега нека направим същото с произволна гора. Виждаме, че с логистична регресия постигаме по-добра точност с по-малко усилия.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(forest.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XOR-проблем\n",
    "Нека сега разгледаме пример, при който линейните модели са по-лоши.\n",
    "\n",
    "Методите за линейна класификация все още дефинират много проста разделителна повърхност - хиперравнина. Най-известният пример за играчка, където класовете не могат да бъдат разделени от хиперравнина (или линия) без грешки, е „проблемът XOR“.\n",
    "\n",
    "XOR е \"изключително ИЛИ\", булева функция със следната таблица на истината:\n",
    "\n",
    "\n",
    "\n",
    "<img src='../../img/XOR_table.gif'>\n",
    "\n",
    "XOR е името, дадено на прост проблем с двоична класификация, в който класовете са представени като диагонално разширени пресичащи се облаци от точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataset\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(200, 2)\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно не може да се начертае една права линия, за да се раздели един клас от друг без грешки. Следователно логистичната регресия се справя зле с тази задача."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, plot_title):\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 3, 50), np.linspace(-3, 3, 50))\n",
    "    clf.fit(X, y)\n",
    "    # plot the decision function for each datapoint on the grid\n",
    "    Z = clf.predict_proba(np.vstack((xx.ravel(), yy.ravel())).T)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    image = plt.imshow(\n",
    "        Z,\n",
    "        interpolation=\"nearest\",\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        cmap=plt.cm.PuOr_r,\n",
    "    )\n",
    "    contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2, linetypes=\"--\")\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(r\"$x_1$\")\n",
    "    plt.ylabel(r\"$x_2$\")\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    plt.colorbar(image)\n",
    "    plt.title(plot_title, fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(\n",
    "    LogisticRegression(solver=\"lbfgs\"), X, y, \"Logistic Regression, XOR problem\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но ако трябва да се дадат полиномни характеристики като вход (тук, до 2 степени), тогава проблемът е решен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pipe = Pipeline(\n",
    "    [\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"logit\", LogisticRegression(solver=\"lbfgs\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(logit_pipe, X, y, \"Logistic Regression + quadratic features. XOR problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тук логистичната регресия все още е създала хиперравнина, но в 6-измерно пространствено пространство $1, x_1, x_2, x_1^2, x_1x_2$ и $x_2^2$. Когато проектираме към оригиналното пространствено пространство, $x_1, x_2$, границата е нелинейна.\n",
    "\n",
    "На практика полиномните характеристики наистина помагат, но е неефективно от изчислителна гледна точка да се създават изрично. SVM с трика на ядрото работи много по-бързо. При този подход се изчислява само разстоянието между обектите (дефинирано от функцията на ядрото) във високомерно пространство и няма нужда да се създава комбинаторно голям брой характеристики. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Демо задание\n",
    "За да практикувате с линейни модели, можете да завършите [това задание](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit), където ще изградите модел за откриване на сарказъм. Заданието е само за упражняване и върви с [решение](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution).\n",
    "\n",
    "## 5. Полезни ресурси\n",
    "- Средна [\"история\"](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-4-linear-classification-and-regression-44a41b9b5220) въз основа на този бележник\n",
    "- Основен курс [сайт](https://mlcourse.ai), [репо за курс](https://github.com/Yorko/mlcourse.ai) и YouTube [канал](https://www.youtube. com/watch?v=QKTuw4PNOsU&list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX)\n",
    "- Материали за курса като [Набор от данни на Kaggle](https://www.kaggle.com/kashnitsky/mlcourse)\n",
    "- Ако четете руски: [статия](https://habrahabr.ru/company/ods/blog/323890/) на Habr.com със ~ същия материал. И [лекция](https://youtu.be/oTXGQ-_oqvI) в YouTube\n",
    "- В книгата [\"Deep Learning\"] (http://www.deeplearningbook.org) (I. Goodfellow, Y. Bengio и A. Courville) е даден хубав и кратък преглед на линейните модели.\n",
    "- Линейните модели са разгледани практически във всяка книга за ML. Препоръчваме „Разпознаване на модели и машинно обучение“ (C. Bishop) и „Машинно обучение: вероятностна гледна точка“ (K. Murphy).\n",
    "- Ако предпочитате задълбочен преглед на линейния модел от гледна точка на статистик, тогава вижте \"Елементите на статистическото обучение\" (T. Hastie, R. Tibshirani и J. Friedman).\n",
    "- Книгата \"Машинно обучение в действие\" (P. Harrington) ще ви преведе през имплементации на класически ML алгоритми в чист Python.\n",
    "- [Scikit-learn](http://scikit-learn.org/stable/documentation.html) библиотека. Тези момчета работят усилено върху писането на наистина ясна документация.\n",
    "- Scipy 2017 [урок за scikit-learn](https://github.com/amueller/scipy-2017-sklearn) от Алекс Грамфорт и Андреас Мюлер.\n",
    "- Още един [ML курс](https://github.com/diefimov/MTH594_MachineLearning) с много добри материали.\n",
    "- [Имплементации](https://github.com/rushter/MLAlgorithms) на много ML алгоритми. Търсете линейна регресия и логистична регресия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
