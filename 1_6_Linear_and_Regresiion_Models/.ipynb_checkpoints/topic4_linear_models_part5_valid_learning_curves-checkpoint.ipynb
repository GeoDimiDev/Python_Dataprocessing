{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Отворен курс за машинно обучение\n",
    "\n",
    "Автор: [Юрий Кашницки](https://yorko.github.io). Превод и редакция от [Christina Butsko](https://www.linkedin.com/in/christinabutsko/), [Nerses Bagiyan](https://www.linkedin.com/in/nersesbagiyan/), [Yulia Klimushina] (https://www.linkedin.com/in/yuliya-klimushina-7168a9139) и [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/). Този материал е предмет на правилата и условията на лиценза [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Безплатното използване е разрешено за всякакви нетърговски цели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 4. Линейна класификация и регресия\n",
    "## <center> Част 5. Валидиране и криви на обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import (LogisticRegression, LogisticRegressionCV,\n",
    "                                  SGDClassifier)\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сега, когато имаме представа за валидиране на модела, кръстосано валидиране и регулиране. Нека разгледаме по-големия въпрос:\n",
    "\n",
    "**Какво да направите, ако качеството на модела е незадоволително?**\n",
    "\n",
    "- Да направим модела по-сложен или по-прост?\n",
    "- Трябва ли да добавим още функции?\n",
    "- Нуждаем ли се просто от повече данни за обучение?\n",
    "\n",
    "Отговорите на тези въпроси не са очевидни. По-специално, понякога по-сложен модел може да доведе до влошаване на производителността. Друг път добавянето на нови наблюдения няма да доведе до забележими промени. Всъщност способността да се вземе правилното решение и да се избере правилният метод за подобряване на модела отличава добрия професионалист от лошия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ние ще работим с нашите данни за оттеглянето на клиенти от телеком оператора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/telecom_churn.csv\").drop(\"State\", axis=1)\n",
    "data[\"International plan\"] = data[\"International plan\"].map({\"Yes\": 1, \"No\": 0})\n",
    "data[\"Voice mail plan\"] = data[\"Voice mail plan\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "y = data[\"Churn\"].astype(\"int\").values\n",
    "X = data.drop(\"Churn\", axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ще обучим логистична регресия със стохастичен градиентен низход. По-късно в курса ще имаме отделна статия по тази тема.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-2, 0, 20)\n",
    "sgd_logit = SGDClassifier(loss=\"log\", n_jobs=-1, random_state=17, max_iter=5)\n",
    "logit_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"sgd_logit\", sgd_logit),\n",
    "    ]\n",
    ")\n",
    "val_train, val_test = validation_curve(\n",
    "    logit_pipe, X, y, \"sgd_logit__alpha\", alphas, cv=5, scoring=\"roc_auc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Като първа стъпка ще изградим валидационни криви, показващи как качеството (ROC-AUC) на тренировъчните и тестови набори варира в зависимост от параметъра за регулиране.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_err(x, data, **kwargs):\n",
    "    mu, std = data.mean(1), data.std(1)\n",
    "    lines = plt.plot(x, mu, \"-\", **kwargs)\n",
    "    plt.fill_between(\n",
    "        x,\n",
    "        mu - std,\n",
    "        mu + std,\n",
    "        edgecolor=\"none\",\n",
    "        facecolor=lines[0].get_color(),\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "\n",
    "plot_with_err(alphas, val_train, label=\"training scores\")\n",
    "plot_with_err(alphas, val_test, label=\"validation scores\")\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"ROC AUC\")\n",
    "plt.legend()\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тенденцията е доста видима и е много разпространена.\n",
    "\n",
    "- За прости модели грешките при обучение и валидиране са близки и големи. Това предполага, че моделът е **недостатъчно**, което означава, че няма достатъчен брой параметри.\n",
    "\n",
    "- За високо сложни модели грешките при обучение и валидиране се различават значително. Това може да се обясни с **прекомерно оборудване**. Когато има твърде много параметри или регулирането не е достатъчно строго, алгоритъмът може да бъде „разсеян“ от шума в данните и да загуби представа за цялостната тенденция."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Колко данни са необходими?\n",
    "\n",
    "Колкото повече данни използва моделът, толкова по-добре. Но как да разберем дали новите данни ще бъдат полезни във всяка дадена ситуация? Например, рационално ли е да похарчите $N$ за оценители, за да удвоите набора от данни?\n",
    "\n",
    "Тъй като новите данни може да не са налични, разумно е да промените размера на набора за обучение и да видите как качеството на решението зависи от количеството данни за обучение. Ето как получаваме **криви на обучение**.\n",
    "\n",
    "Идеята е проста: показваме грешката като функция от броя на примерите, използвани в обучението. Параметрите на модела са фиксирани предварително."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(degree=2, alpha=0.01):\n",
    "    train_sizes = np.linspace(0.05, 1, 20)\n",
    "    logit_pipe = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "            (\n",
    "                \"sgd_logit\",\n",
    "                SGDClassifier(n_jobs=-1, random_state=17, alpha=alpha, max_iter=5),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    N_train, val_train, val_test = learning_curve(\n",
    "        logit_pipe, X, y, train_sizes=train_sizes, cv=5, scoring=\"roc_auc\"\n",
    "    )\n",
    "    plot_with_err(N_train, val_train, label=\"training scores\")\n",
    "    plot_with_err(N_train, val_test, label=\"validation scores\")\n",
    "    plt.xlabel(\"Training Set Size\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нека да видим какво получаваме за линейния модел. Ще зададем коефициента на регулация да бъде доста голям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(degree=2, alpha=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типична ситуация: за малко количество данни, грешките между наборите за обучение и кръстосано валидиране са доста различни, което показва пренастройване. За същия този модел, но с голямо количество данни, грешките се „сближават“, което показва недостатъчно монтиране.\n",
    " \n",
    "Ако добавим повече данни, грешката в набора за обучение няма да се увеличи. От друга страна, грешката в данните от теста няма да бъде намалена.\n",
    " \n",
    "И така, виждаме, че грешките са \"конвергирани\" и добавянето на нови данни няма да помогне. Всъщност този случай е най-интересен за бизнеса. Възможно е да увеличим размера на набора от данни с 10 пъти, но без да променяме сложността на модела, тези допълнителни данни може да не помогнат. Следователно стратегията „задайте веднъж, след това използвайте 10 пъти“ може да не работи.\n",
    " \n",
    "Какво се случва, ако намалим коефициента на регулация до 0,05?\n",
    " \n",
    "Виждаме добра тенденция - кривите постепенно се сближават и ако се придвижим по-надясно, т.е. добавим повече данни към модела, можем да подобрим още повече качеството на набора за валидиране. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(degree=2, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ами ако направим модела още по-сложен, като зададем алфа = 10-4?\n",
    "\n",
    "Вижда се прекомерно оборудване - AUC намалява както при тренировъчните, така и при валидиращите комплекти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(degree=2, alpha=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конструирането на тези криви може да помогне да се разбере кой път да се върви и как правилно да се коригира сложността на модела за нови данни."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключения относно кривите на обучение и валидиране:**\n",
    "\n",
    "\n",
    "- Грешка в комплекта за обучение не говори нищо за качеството на модела сама по себе си\n",
    "- Грешка при кръстосано валидиране показва колко добре моделът отговаря на данните (съществуващата тенденция в данните), като същевременно запазва способността за обобщаване към нови данни\n",
    "- **Валидационна крива** е графика, показваща резултатите от наборите за обучение и валидиране в зависимост от **сложността на модела**:\n",
    "    + ако двете криви са близо една до друга и двете грешки са големи, това е знак за *недостатъчно прилягане*\n",
    "    + ако двете извивки са далече една от друга, това е признак на *пренапасване*\n",
    "- **Кривата на обучението** е графика, показваща резултатите от наборите за обучение и валидиране в зависимост от броя на наблюденията:\n",
    "    + ако кривите се сближават, добавянето на нови данни няма да помогне и е необходимо да се промени сложността на модела\n",
    "    + ако кривите не са се сближили, добавянето на нови данни може да подобри резултата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезни ресурси\n",
    "- Основен курс [сайт](https://mlcourse.ai), [репо за курс](https://github.com/Yorko/mlcourse.ai) и YouTube [канал](https://www.youtube. com/watch?v=QKTuw4PNOsU&list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX)\n",
    "- Средна [\"история\"](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-4-linear-classification-and-regression-44a41b9b5220) въз основа на този бележник\n",
    "- Материали за курса като [Набор от данни на Kaggle](https://www.kaggle.com/kashnitsky/mlcourse)\n",
    "- Ако четете руски: [статия](https://habrahabr.ru/company/ods/blog/323890/) на Habrahabr със ~ същия материал. И [лекция](https://youtu.be/oTXGQ-_oqvI) в YouTube\n",
    "- Хубав и кратък преглед на линейните модели е даден в книгата [“Deep Learning”](http://www.deeplearningbook.org) (I. Goodfellow, Y. Bengio и A. Courville).\n",
    "- Линейните модели са разгледани практически във всяка книга за ML. Препоръчваме „Разпознаване на модели и машинно обучение“ (C. Bishop) и „Machine Learning: A Probabilistic Perspective“ (K. Murphy).\n",
    "- Ако предпочитате задълбочен преглед на линейния модел от гледна точка на статистик, тогава вижте „Елементите на статистическото обучение“ (T. Hastie, R. Tibshirani и J. Friedman).\n",
    "- Книгата „Машинно обучение в действие“ (P. Harrington) ще ви преведе през имплементации на класически ML алгоритми в чист Python.\n",
    "- [Scikit-learn](http://scikit-learn.org/stable/documentation.html) библиотека. Тези момчета работят усилено върху писането на наистина ясна документация.\n",
    "- Scipy 2017 [урок за scikit-learn](https://github.com/amueller/scipy-2017-sklearn) от Алекс Грамфорт и Андреас Мюлер.\n",
    "- Още един [ML курс](https://github.com/diefimov/MTH594_MachineLearning) с много добри материали.\n",
    "- [Имплементации](https://github.com/rushter/MLAlgorithms) на много ML алгоритми. Търсете линейна регресия и логистична регресия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "name": "lesson7_part5_overfitting_validation.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
