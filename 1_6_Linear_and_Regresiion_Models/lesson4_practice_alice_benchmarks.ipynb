{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Отворен курс по машинно обучение. Сесия №2\n",
    "</center>\n",
    "Автор на материала: Юрий Исаков и Юрий Кашницки. Материалът се разпространява съгласно условията на лиценза [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можете да го използвате за всякакви цели (редактиране, коригиране и използване като основа), освен търговски, но със задължителното споменаване на автора на материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 4. Линейна класификация и регресионни модели\n",
    "## <center> Практикувайте. Идентификация на потребителя чрез логистична регресия\n",
    "\n",
    "Тук ще възпроизведем няколко бенчмарка от нашата конкуренция и ще се вдъхновим да победим третия бенчмарк, както и останалите участници. Тук няма да има уеб формуляр за изпращане на отговори, референтната точка е [табло за класиране](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session -tracking2/ класация) състезание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Зареждане и конвертиране на данни\n",
    "Регистрирайте се в [Kaggle](www.kaggle.com), ако не сте го направили преди, отидете на [страница](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder - конкуренция за откриване-чрез-проследяване-на-сесия на уеб страница2) и изтегляне на данните. Първо, нека заредим примерите за обучение и тест и да разгледаме данните."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/train_sessions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# тренировъчни и тестови проби за натоварване\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/train_sessions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/test_sessions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# конвертиране на колони time1, ..., time10 във формат на време\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/train_sessions.csv'"
     ]
    }
   ],
   "source": [
    "# тренировъчни и тестови проби за натоварване\n",
    "train_df = pd.read_csv(\"../../data/train_sessions.csv\", index_col=\"session_id\")\n",
    "test_df = pd.read_csv(\"../../data/test_sessions.csv\", index_col=\"session_id\")\n",
    "\n",
    "# конвертиране на колони time1, ..., time10 във формат на време\n",
    "times = [\"time%s\" % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# сортирайте данните по време\n",
    "train_df = train_df.sort_values(by=\"time1\")\n",
    "\n",
    "# погледнете заглавката на примера за обучение\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учебният комплект съдържа следните характеристики:\n",
    "    - site1 – индекс на първия посетен сайт в сесията\n",
    "    - time1 – време на посещение на първия сайт в сесията\n",
    "    - ...\n",
    "    - site10 – индекс на 10-ия посетен сайт в сесията\n",
    "    - time10 – време на посещение на 10-ия сайт в сесията\n",
    "    - target – целева променлива, 1 за сесии на Alice, 0 за сесии на други потребители\n",
    "    \n",
    "Потребителските сесии се разпределят по такъв начин, че не могат да бъдат по-дълги от половин час или 10 сайта. Тоест, сесията се счита за приключила, когато потребителят е посетил 10 сайта подред или когато сесията е отнела повече от 30 минути.\n",
    "\n",
    "В таблицата има липсващи стойности, което означава, че сесията се състои от по-малко от 10 сайта. Нека заменим липсващите стойности с нули и преобразуваме характеристиките в целочислен тип. Нека също да изтеглим речника на сайтовете и да видим как изглежда:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# конвертирайте колоните site1, ..., site10 в целочислен формат и заменете пропуските с нули\n",
    "sites = [\"site%s\" % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype(\"int\")\n",
    "test_df[sites] = test_df[sites].fillna(0).astype(\"int\")\n",
    "\n",
    "# заредете речника на сайтовете\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# рамка с данни на речника на сайта\n",
    "sites_dict_df = pd.DataFrame(\n",
    "    list(site_dict.keys()), index=list(site_dict.values()), columns=[\"site\"]\n",
    ")\n",
    "print(u\"всего сайтов:\", sites_dict_df.shape[0])\n",
    "sites_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нека да изолираме целевата променлива и да комбинираме извадките, за да ги обединим в разреден формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нашата целева променлива\n",
    "y_train = train_df[\"target\"]\n",
    "\n",
    "# таблица с обединени изходни данни\n",
    "full_df = pd.concat([train_df.drop(\"target\", axis=1), test_df])\n",
    "\n",
    "# индекс, с който ще отделим обучителната от тестовата\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За първия модел ще използваме само посетени сайтове в сесията (но няма да обръщаме внимание на временни знаци). Идеята зад този избор на данни за модела е: *Алис има своите любими сайтове и колкото по-често виждате тези сайтове в сесия, толкова по-голяма е вероятността това да е сесията на Алис и обратното.*\n",
    "\n",
    "Нека подготвим данните и от цялата таблица изберем само атрибутите `site1, site2, ..., site10`. Спомнете си, че липсващите стойности се заменят с нула. Ето как изглеждат първите редове на таблицата:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# табела с индекси на посетените сайтове в сесията\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сесиите са поредица от индекси на сайтове и данните в тази форма са неудобни за линейни методи. В съответствие с нашата хипотеза (Алиса има своите любими сайтове), трябва да трансформираме тази таблица по такъв начин, че всеки възможен сайт да има свой отделен атрибут (колона) и стойността му да е равна на броя посещения на този сайт в сесия. Това се прави на два реда:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# последователност с индекси\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# необходима матрица\n",
    "full_sites_sparse = csr_matrix(\n",
    "    (\n",
    "        [1] * sites_flatten.shape[0],\n",
    "        sites_flatten,\n",
    "        range(0, sites_flatten.shape[0] + 10, 10),\n",
    "    )\n",
    ")[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Друго предимство на използването на разредени матрици е, че за тях има специални реализации както на матрични операции, така и на алгоритми за машинно обучение, което понякога позволява значително ускоряване на операциите поради особеностите на структурата на данните. Това важи и за логистичната регресия. Сега всички сме готови да изградим първия си модел.\n",
    "\n",
    "### 2. Изграждане на първия модел\n",
    "\n",
    "И така, имаме алгоритъм и данни за него, нека изградим нашия първи модел, използвайки версията [логистична регресия](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) от `package sklearn` с параметри по подразбиране. Ще използваме първите 90% от данните за обучение (наборът за обучение е сортиран по време), а останалите 10% за проверка на качеството (валидиране).\n",
    "\n",
    "**Напишете проста функция, която ще върне качеството на модела на забавена извадка и обучете нашия първи класификатор**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio=0.9, seed=17):\n",
    "\"\"\"\n",
    "    X, y – образец\n",
    "    съотношение – в какво съотношение да се раздели пробата\n",
    "    C, seed – коефициент на регулация и random_state\n",
    "              логистична регресия\n",
    "    \"\"\"\n",
    "\n",
    "    # Вашият код е тук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вижте как се оказа ROC AUC на забавената проба.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вашият код е тук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нека разгледаме този модел като нашата първа отправна точка (базова линия). За да се изгради модел за предсказване върху тестова извадка **необходимо е моделът да се обучи отново върху целия набор за обучение** (досега нашият модел беше обучен само върху част от данните), което ще увеличи способността му за обобщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(\n",
    "    predicted_labels, out_file, target=\"target\", index_label=\"session_id\"\n",
    "):\n",
    "    predicted_df = pd.DataFrame(\n",
    "        predicted_labels,\n",
    "        index=np.arange(1, predicted_labels.shape[0] + 1),\n",
    "        columns=[target],\n",
    "    )\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучете модела върху цялата извадка, направете прогноза за тестовия набор и изпратете на състезанието**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вашият код е тук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ако следвате тези стъпки и качите отговора на състезателната [страница](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) след това пуснете първия бенчмарк \"Logit\".\n",
    "\n",
    "### 3. Подобряване на модела, изграждане на нови функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Създайте знак, който ще бъде число от вида ГГГГММ от датата на провеждане на сесията, например 201407 - 2014 година и 7 месеца. По този начин ще вземем предвид месечната [линейна тенденция](http://people.duke.edu/~rnau/411trend.htm) за целия период на предоставените данни."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вашият код е тук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавете нова функция, като преди това сте я мащабирали с помощта на `StandardScaler`, и отново изчислете ROC AUC върху забавената проба."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вашият код е тук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавете две нови функции: начален_час и сутрин.**\n",
    "\n",
    "Атрибутът `start_hour` е часът, в който е започнала сесията (от 0 до 23), а двоичният атрибут `morning` е равен на 1, ако сесията е започнала сутринта и 0, ако сесията е започнала по-късно (ще приемем, че сутрин е, ако `начален_час е равен на` 11 или по-малко).\n",
    "\n",
    "**Изчислете ROC AUC на забавена проба за проба с:**\n",
    "- сайтове, `начален_месец` и `начален_час`\n",
    "- сайтове, `начален_месец` и `сутрин`\n",
    "- сайтове, `начален_месец`, `начален_час` и `сутрин`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вашият код е тук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Избор на коефициент на регуляризация\n",
    "\n",
    "И така, въведохме функции, които подобряват качеството на нашия модел в сравнение с първата базова линия. Можем ли да постигнем по-висока метрична стойност? След като сме формирали тренировъчната и тестовата извадка, почти винаги има смисъл да избираме оптимални хиперпараметри - характеристики на модела, които не се променят по време на обучението. Например, през седмица 3 сте преминали през решаващи дървета, дълбочината на дървото е хиперпараметър, но знакът, по който се извършва разклоняването, и неговата стойност не са. В логистичната регресия, която използваме, теглата на всяка характеристика се променят и техните оптимални стойности се намират по време на обучението, докато коефициентът на регулация остава постоянен. Това е хиперпараметърът, който сега ще оптимизираме.\n",
    "\n",
    "Изчислете качеството на забавена проба с коефициент на регулиране, който по подразбиране е „C=1“:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вашият код е тук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ще се опитаме да победим този резултат чрез оптимизиране на коефициента на регулация. Нека вземем набор от възможни стойности на C и за всяка от тях изчислим метричната стойност на забавена проба.\n",
    "\n",
    "Намерете „C“ от „np.logspace(-3, 1, 10)“, при което ROC AUC на забавената проба е максимизирана."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вашият код е тук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Накрая, обучете модела с намерената оптимална стойност на коефициента на регулация и с конструираните характеристики `начален_час`, `начален_месец` и `сутрин`. Ако сте направили всичко правилно и сте изтеглили това решение, повторете втория бенчмарк от състезанието."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вашият код е тук"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
