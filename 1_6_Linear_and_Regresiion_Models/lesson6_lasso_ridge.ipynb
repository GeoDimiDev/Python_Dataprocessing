{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Отворен курс по машинно обучение\n",
    "Автор на материала: програмист-изследовател в Mail.ru Group, старши преподавател във Факултета по компютърни науки на Висшето училище по икономика Юрий Кашницки. Материалът се разпространява съгласно условията на лиценза [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можете да го използвате за всякакви цели (редактиране, коригиране и използване като основа), освен търговски, но със задължителното споменаване на автора на материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Тема 6. Проблем с възстановяване чрез регресия</center>\n",
    "## <center>Регресия с ласо и хребет</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cycler import cycler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ще работим с набор от данни за цените на жилищата в Бостън (UCI хранилище).**\n",
    "**Зареждане на данни.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X, y = boston[\"data\"], boston[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прочетете описанието на набора от данни:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Знаци:**\n",
    "- CRIM - брой престъпления на глава от населението\n",
    "- ZN - процент на жилищни парцели с площ над 25 хиляди квадратни метра. фута (~ 23 акра)\n",
    "- INDUS - процент площи за търговия на едро\n",
    "- ЧАС - тече ли реката?\n",
    "- NOX - концентрация на азотни оксиди\n",
    "- RM - среден брой помещения в сградата\n",
    "- AGE - дял на сградите, построени преди 1940г\n",
    "- DIS - претеглено разстояние до 5 бизнес центъра в Бостън\n",
    "- RAD - индекс на достъпност на магистралата\n",
    "- TAX - данъчно ниво\n",
    "- PTRATIO - среден брой ученици на учител\n",
    "- B - процент на афроамериканците\n",
    "- LSTAT - процент на гражданите с нисък стандарт на живот\n",
    "- MEDV (target) - средна стойност на къщите в района"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нека да разгледаме първите 2 записа.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso-регресия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ласо регресията решава проблема с минимизирането на средната квадратична грешка с L1 регулация:\n",
    "$$\\Large error(X, y, w) = \\frac{1}{2} \\sum_{i=1}^\\ell {(y_i - w^Tx_i)}^2 + \\alpha \\sum_{i=1}^d |w_i|$$\n",
    "\n",
    "където $y = w^Tx$ е уравнението на хиперравнината в зависимост от параметрите на модела $w$, $\\ell$ е броят на обектите в извадката $X$, $d$ е броят на характеристиките, $y$ е стойностите на целевата характеристика, $\\ alpha$ – коефициент на регулация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нека тренираме регресия на Ласо с малък коефициент $\\alpha$ (слаба регуляризация). Нулира се само коефициентът за атрибута NOX (концентрация на азотни оксиди). Това означава, че е най-малко важно за прогнозиране на целевия атрибут - средната цена на къщите в района.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нека обучим регресия на Ласо с коефициент $\\alpha=10$. Сега ненулевите коефициенти остават само за следните характеристики: ZN (процент на жилищни парцели с площ над 25 хиляди квадратни фута), TAX (данъчно ниво), B (процент на афро-американците) и LSTAT (процент на гражданите с нисък стандарт на живот).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=10)\n",
    "lasso.fit(X, y)\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**По този начин регресията с ласо служи като метод за избор на характеристики.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "alphas = np.linspace(0.1, 10, n_alphas)\n",
    "model = Lasso()\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(X, y)\n",
    "    coefs.append(model.coef_)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_prop_cycle(cycler(\"color\", [\"b\", \"r\", \"g\", \"c\", \"k\", \"y\", \"m\"]))\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"weights\")\n",
    "plt.title(\"Lasso coefficients as a function of the regularization\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сега ще определим най-добрата $\\alpha$ стойност чрез процеса на кръстосано валидиране.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(alphas=alphas, cv=3, random_state=17)\n",
    "lasso_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Методът `cross_val_score` максимизира показателя, така че вместо\n",
    "минимизирайки MSE, ние ще максимизираме отрицателната MSE – `neg_mean_squared_error`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(Lasso(lasso_cv.alpha_), X, y, cv=3, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**За да продължим да интерпретираме резултата по отношение на MSE, ще покажем модула на средната стойност на показателя `neg_mean_squared_error` за кръстосано валидиране.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(\n",
    "    np.mean(\n",
    "        cross_val_score(\n",
    "            Lasso(lasso_cv.alpha_), X, y, cv=3, scoring=\"neg_mean_squared_error\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(np.mean(cross_val_score(Lasso(9.95), X, y, cv=3, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Друга двусмислена точка: LassoCV сортира стойностите на параметрите в низходящ ред - това улеснява оптимизирането. Това може да накара оптимизирането на параметъра $\\alpha$ да изглежда неправилно**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.alphas[:10]  # значения параметров на входе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.alphas_[:10]  # преобразованные значения параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lasso_cv.alphas, lasso_cv.mse_path_.mean(1))  # неверно\n",
    "plt.axvline(lasso_cv.alpha_, c=\"g\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lasso_cv.alphas_, lasso_cv.mse_path_.mean(1))  # верно\n",
    "plt.axvline(lasso_cv.alpha_, c=\"g\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge-регресия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ридж регресията (или ридж регресията) решава проблема с минимизирането на средната квадратична грешка с L2 регулация:\n",
    "$$\\Large error(X, y, w) = \\frac{1}{2} \\sum_{i=1}^\\ell {(y_i - w^Tx_i)}^2 + \\alpha \\sum_{i= 1}^d w_i^2$$\n",
    "\n",
    "където $y = w^Tx$ е уравнението на хиперравнината в зависимост от параметрите на модела $w$, $\\ell$ е броят на обектите в извадката $X$, $d$ е броят на характеристиките, $y$ е стойностите на целевата характеристика, $\\ alpha$ – коефициент на регулация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn прилага специален клас [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV) за кръстосано валидиране с регресия на Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "ridge_alphas = np.logspace(-2, 6, n_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(alphas=ridge_alphas, scoring=\"neg_mean_squared_error\", cv=3)\n",
    "ridge_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В случай на регресия на Ридж, никакви параметри не са зададени на нула - те могат да бъдат много малки, но не и нула.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "ridge_alphas = np.logspace(-2, 6, n_alphas)\n",
    "model = Ridge()\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(X, y)\n",
    "    coefs.append(model.coef_)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_prop_cycle(cycler(\"color\", [\"b\", \"r\", \"g\", \"c\", \"k\", \"y\", \"m\"]))\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"weights\")\n",
    "plt.title(\"Ridge coefficients as a function of the regularization\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Връзки\n",
    "- [Обобщени линейни модели (GLM) в Scikit-learn\n",
    "- [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression), [Lasso](http://scikit-learn.org/ stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso), [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn .linear_model.LassoCV), [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) и [RidgeCV](http://scikit-learn.org/stable /modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV) в Scikit-learn\n",
    "- [Статия](https://habrahabr.ru/post/264915/) „Методи за избор на функции“ на Habrahabr със споменаване на регресията с ласо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "name": "lesson8_part1_kmeans.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
